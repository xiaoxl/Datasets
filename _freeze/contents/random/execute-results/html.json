{
  "hash": "02bfccf84daf5dcf60d20b8221da052c",
  "result": {
    "markdown": "# Randomly generated datasets\n## `make_moon` dataset\n\nThis is used to generate two interleaving half circles.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n```\n:::\n\n\n## `make_gaussian_quantiles` dataset\n\nThis is a generated isotropic Gaussian and label samples by quantile. \n\nThe following code are from [this page](https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_twoclass.html#sphx-glr-auto-examples-ensemble-plot-adaboost-twoclass-py). It is used to generate a relative complex dataset by combining two datesets together.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_gaussian_quantiles\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\nX1, y1 = make_gaussian_quantiles(cov=2.0, n_samples=200, n_features=2,\n                                 n_classes=2, random_state=1)\nX2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5, n_samples=300,\n                                 n_features=2, n_classes=2, random_state=1)\nX = np.concatenate((X1, X2))\ny = np.concatenate((y1, -y2 + 1))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n```\n:::\n\n\nIt can also be used to generate multiclass dataset.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_gaussian_quantiles\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_gaussian_quantiles(cov=2.0, n_samples=200, n_features=2,\n                               n_classes=4, random_state=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n```\n:::\n\n\n## `make_classification`\n  \nThis will create a multiclass dataset. Without shuffling, `X` horizontally stacks features in the following order: the primary `n_informative` features, followed by `n_redundant` linear combinations of the informative features, followed by `n_repeated` duplicates, drawn randomly with replacement from the informative and redundant features. \n\nFor more details please see the [official document](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification).\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\n\nX, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=2, n_repeated=2, n_classes=3, n_clusters_per_class=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n```\n:::\n\n\n",
    "supporting": [
      "random_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}