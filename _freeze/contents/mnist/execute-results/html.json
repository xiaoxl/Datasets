{
  "hash": "8270b988687dd96ee7be591bb145c2cc",
  "result": {
    "engine": "jupyter",
    "markdown": "# `MNIST` dataset\nThis is a famous dataset for handwritten digits recognition. More info can be found from [its website](https://yann.lecun.com/exdb/mnist/).\nThere are several versions of the dataset (that almost all machine learning libraries have it in their datasets). Here I provide the version from Huggingface Hub. The tensorflow version is outdated but kept here for reference.\n\n\n## Huggingface Hub\nThe dataset and description can be found from the [Hugging Face hub](https://huggingface.co/datasets/ylecun/mnist). You may use the following code to load the dataset. The installation guide of the `datasets` library can be found in its [homepage](https://huggingface.co/docs/datasets/en/installation).\n\n::: {#657b23fb .cell execution_count=1}\n``` {.python .cell-code}\nfrom datasets import load_dataset\n\nmnist_train = load_dataset(\"ylecun/mnist\", split='train', streaming=True)\nmnist_test = load_dataset(\"ylecun/mnist\", split='test', streaming=True)\n```\n:::\n\n\nThe loaded datasets contains images. We may directly visualize it. Note that we load the dataset in streaming mode, so it is a generator and will give images one by one.\n\n::: {#f8cdbc2c .cell execution_count=2}\n``` {.python .cell-code}\nnextdata = next(iter(mnist_train))\npic = nextdata['image']\nlabel = nextdata['label']\npic\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n![](mnist_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\n::: {#9ce1c19d .cell execution_count=3}\n``` {.python .cell-code}\nlabel\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n5\n```\n:::\n:::\n\n\nIf we want to use the data, we would like to turn them into matrices. Here we directly flatten the images into row vectors.\n\n::: {#bed85b8e .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\n\ndef stream_to_array(streaming):\n    pic_list = []\n    label_list =[]\n    for data in streaming:\n        pic_list.append(np.array(data['image']).reshape(-1))\n        label_list.append(data['label'])\n    return np.array(pic_list), np.array(label_list)\n\nX_train, y_train = stream_to_array(mnist_train)\nX_test, y_test = stream_to_array(mnist_test)\n```\n:::\n\n\nWe could check the size of these data.\n\n::: {#80bdeaad .cell execution_count=5}\n``` {.python .cell-code}\nprint(f\"The size of training features is {X_train.shape}.\")\nprint(f\"The size of training labels is {y_train.shape}.\")\nprint(f\"The size of testing features is {X_test.shape}.\")\nprint(f\"The size of testing labels is {y_test.shape}.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe size of training features is (60000, 784).\nThe size of training labels is (60000,).\nThe size of testing features is (10000, 784).\nThe size of testing labels is (10000,).\n```\n:::\n:::\n\n\n## `tensorflow` version (possibly outdated)\n`tensorflow`/`keras` provides the data with the original split. This version is not recommended since `keras` changed a lot during recent updates so if you use newer version the following code might not work. In addition it takes a long time to install `tensorflow` library.\n\n::: {#9d08b6e6 .cell execution_count=6}\n``` {.python .cell-code}\nimport tensorflow.keras as keras\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n```\n:::\n\n\n",
    "supporting": [
      "mnist_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}